# Report sobre el conjunt de dades `diamonds`

## Context

`diamonds` és un datasaet del paquet ggplot2 que descriu 54000 diamants. Aquest és un dataset del 2008 fet per [Solomon](https://rpubs.com/anthonycerna/diamondspredictions), tot i que no he trobat massa informació sobre l'origen del dataset. La idea d'aquest informa és analitzar aquest dataset, veure quines features són més rellevants a l'hora de determinar el preu i mirar de fer algun model predictiu.


```{r include = FALSE}
knitr::opts_chunk$set(fig.align='center', echo=FALSE, message=FALSE, warning=FALSE)
```

```{r}
require('ggplot2')
require('corrplot')
require('ggridges')
require('ggpubr')
require('viridis')
require('tidyverse')
require('relaimpo')
require('ranger')
require('splitTools')

```

```{r}
library(ggplot2)
library(corrplot)
library(ggridges)
library(ggpubr)
library(viridis)
library(tidyverse)
library(dplyr)
library(relaimpo)
library(ranger)
library(splitTools)

data(diamonds)
```

## Referències

L'anàlisi del dataset ha seguit força els articles següents:

- [Garg - Diamonds what determines their price](https://12ft.io/proxy?q=https%3A%2F%2Fmedium.com%2Fcodex%2Fdiamonds-what-determines-their-price-264a83c7f61a)
- [Napitupulu - Diamonds' Analysis](http://napitupulu-jon.appspot.com/posts/diamonds-analysis.html)
- [Cerna - Diamonds Predictions](https://rpubs.com/anthonycerna/diamondspredictions)
- [Mayer - A curious fact on the diamonds dataset](https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/)
- [Diamond Search Engine](https://www.diamondse.info)
- [Standford dcl model](https://dcl-model.stanford.edu/understand_your_data.html)

En especial el segon i quart article. Recomanem que no llegiu l'article de Mayer fins al final de l'informe.

## Introducció

En aquest informe primer farem un anàlisi del dataset `diamonds`, a continuació veurem quines variables són més importants per explicar el preu d'un diamant i finalment calcularem algun model de predicció

## Anàlisi del dataset

### Exploració superficial

```{r}
glimpse(diamonds)
```

D'entrada podem veure que el dataset té 10 característiques de les quals tres són categòriques i la majoria són quantitatives.

La majoria podem endevinar a què fan referència. El color i el preu es refereixen al color del diamant i el preu de venta. Si explorem el color veiem que el rang de la variable és de D a J. Segons [Diamonds Search Engine](https://www.diamondse.info/diamonds-color.asp), la D és sense color i la J és el rang més opac dels que no tenen color.

El tall és una variable categòrica describint la qualitat del tall i la claredat també. Els millors talls fan diamants més simètrics i lluminosos, mentre que la claredat es veu influenciada per microescletxes i imperfeccions del diamant, i per tant, com menys imperfeccions tenim millor és la claredat (`IF`) i viceversa (`I1`) ([Claredat](https://www.diamondse.info/diamonds-clarity.asp)).

Pel què fa a les dimensions, tenim x, y, z, table, depth i carat. x, y i z són les dimensions màximes/externes del diamant i taula i profunditat les mínimes/internes. La [imatge 1](#dimensions) il·lustra bé les dimensions.

Finalment el pes d'un diamant es mesura en carats.

[]{#dimensions}

<center>
![Imatge 1: Explicació de les dimensions d'un diamant](https://raw.githubusercontent.com/polmonso/bigdata/master/images/diamonds.png)
</center>

La variable que més estudiarem serà la del preu. De quines variables depèn més? Quines són poc rellevants? D'entrada podem fer una ullada a la distribució d'aquest preu [[Imatge 1](#distribucio)] i observar que la majoria de diamants es venen per menys de dos mil dòlars i que per sobre de cinc mil tenim una cua exponencialment decreixent amb poca freqüència que s'allarga fins a 18000 US$. En general la corba és exponencial decreixent amb un petit *plateau* de dos mil a cinc mil.

[]{#distribucio}

```{r foo,fig.cap="Imatge 1: Distribució del preu"}
ggplot(diamonds) + geom_histogram(aes(x = price)) + xlab("Preu del Diamant [US$]") + ylab("Freqüència")
```

Aquesta distribució tant esbiaixada fa que la mitjana i la mediana singuin molt diferents (3962.8 i 2401 respectivament), fent de la mediana més representativa de la centralitat de les valors.

## Creuament de dades

### Variables númeriques

Un cop ja hem fet una ullada a la distribució del preu i tenim una idea del què podem esperar podem explorar la correlació entre les variables que composen el dataset. Com més correlades estiguin més grans ens sortiran els cercles del gràfic de correlació [[Imatge 2](#correlacio)]. Això ens permetrà tenir una idea de quines variables númeriques són les més rellevants en determinar el preu.

[]{#correlacio}

```{r fig.cap="Imatge 2: Correlació de variables"}
num.Cols <- diamonds[,sapply(diamonds,is.numeric)]
corrplot(cor(num.Cols), method = "circle", type = "upper", addCoef.col = "black")
```

D'entrada ja podem veure que preu està fortament correlat amb les dimensions (x, y, z) i sobretot els carats. No és sorprenent que com més gran sigui el diamant, més car sigui, i també podem veure que més volum implica més carats de pes.

Una altra conclusió que podem treure, tot i que no correlaciona amb el preu, és que a major profunditat, menys taula té el diamant.

### Variables categòriques

Les variables categòriques són les que resultaran més interessants donat que llur correlació amb el preu és menys evident. El que farem per anàlitzar el tall, el color i la claredat és mostrar la distribució del preu per a cada valor de variable categòrica [[Imatge 3](#catcorr)].

Per a fer-ho dibuixarem la distribució del preu condicionada per la variable categòrica i també el diagrama de caixes per veure la mediana, els quantils i els valors més extrems (que, amb la distribució dels preus de l'anàlisi preliminar, ja podem anticipar que seràn a la part més cara del gràfic).

[]{#catcorr}

```{r fig.cap="Imatge 3: Correlació amb el tall"}
p1 <- ggplot(diamonds, aes(x = price, y = cut, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) +
  ggtitle("Ridge plot preu del diamant per tall")

cut_median <- summarise(group_by(diamonds, cut), MD = median(price))

p2 <- ggplot(diamonds) +
  geom_boxplot(aes(x = cut, y = price, color = cut)) +
  ggtitle("Preu del diamant per tall") +
  geom_text(data = cut_median, aes(cut, MD, label = MD), position = position_dodge(width = 0.8), size = 3, vjust = -0.5)

ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

Curiosament, el tall `Fair` és el què millor mediana té, contràriament al que hom esperaria. També és el que queda més concentrat. És potser perquè en realitat les altres variables són més importants? Explorem el color a la [[Imatge 4](#catcorrcolor)].

[]{#catcorrcolor}

```{r fig.cap="Imatge 4: Correlació amb el color"}
#price vs color
p1<- ggplot(diamonds, aes(x = price, y = color, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) +
  ggtitle("Ridge plot Price vs Color")

color_median <- summarise(group_by(diamonds, color), MD = median(price))

p2 <- ggplot(diamonds) +geom_boxplot(aes(x = color, y = price, color = color)) +
  ggtitle("Boxplot Price vs Color") +
  geom_text(data = color_median, aes(color, MD, label = MD), position = position_dodge(width = 0.8), size = 3, vjust = -0.5)

ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

Aquí també tenim una sorpresa, hom pensaria que un diamant totalment transparent seria millor, però resulta que són més cars els que tenen una lleugera opacitat, tot i ser transparents. El [Diamond Search Engine](https://www.diamondse.info/diamonds-color.asp) deia que els diamands transparents (`D`) eren els més rars, però si fem un plot de la distribució per color [[Imatge 5](#districolor)], no sembla ser així en el nostre dataset.

[]{#districolor}

```{r fig.cap="Imatge 5: Distribució del color en el dataset"}
diamonds %>%
    ggplot(aes(color)) +
    geom_bar()
```

I finalment, si estudiem la claredat ([[Imatge 6](#catcorrclar)]), la claredat més valorada és la `S12`, donat que té la mediana més alta, seguit de `I1` i `SI1`. A més a més, podem veure en la distribució de l'`SI2` i l'`I1` que tenen més diamants en el sector més car en contraposició a les altres claredats, que tenen més concentració en el preu per sota de 2000. Qui més concentrat està en la part baixa són les claredats `IF` i `VVS1`.

[]{#catcorrclar}

```{r fig.cap="Imatge 6: Correlació amb la claredat"}
#price vs clarity
p1<- ggplot(diamonds, aes(x = price, y = clarity, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) + ggtitle("Ridge plot Price vs Clarity")
clarity_median <- summarise(group_by(diamonds, clarity), MD = median(price))
p2 <- ggplot(diamonds) +geom_boxplot(aes(x = clarity, y = price, color = clarity)) + ggtitle("Boxplot Price vs Clarity") +
  geom_text(data = clarity_median, aes(clarity, MD, label = MD),
            position = position_dodge(width = 0.8), size = 3, vjust = -0.5)
ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

## Models predictius

Un cop feta l'exploració del dataset, podem passar a mirar de determinar quina de les variables és més rellevant per determinar el preu d'un diamant.

Per a fer-ho, començarem per mirar d'encaixar una regressió lineal amb les dades i n'observarem la coincidència [[Imatge 7](#lm)].

### Linear modeling

[]{#lm}

```{r fig.cap="Imatge 7: Fitting d'un model lineal", echo = TRUE}
lmMod <- lm(price~., data=diamonds)
summary(lmMod)
```

Aquest senzill model de regressió lineal explica el ~91% del preu basant-se en les altres variables. Dit d'una altra manera, donades unes dimensions, claredat, etc. si ho multipliquem per l'estimació dels coeficients resultat de la regressió i hi sumem l'intercept, tindrem una estimació del preu que tindria aquell hipotètic diamant.

També podríem mirar de millorar la regressió a partir de _least squares_ i seleccionar variables [[Imatge 8](#lmlog)], o bé mirar de quadrar un model bayesià com `stan_glm` del paquet `rstanarm`.

[]{#lmlog}

```{r fig.cap="Imatge 8: Fitting d'un model lineal via least squares respecte els carats", echo = TRUE}
lmMod <- lm(log(price) ~ log(carat), data=diamonds)
summary(lmMod)
```

Però el què ens interessa evaluar és la importància de cada variable per a saber millor de què depèn el preu i respondre la pregunta de la què hem partit en el nostre anàlisi. Per a fer-ho ho passem per la funció `relaimpo` que ens mostra que la importància relativa de cada variable [[Imatge 9](#relaimpo)].

[]{#relaimpo}

```{r fig.cap="Imatge 9: Importància de cada variable en la regressió"}
lmMod <- lm(price~., data=diamonds)

importance <- calc.relimp(lmMod, type = "lmg", rela = F)

plot(importance)
```

Ja podem veure que la tria de la segona regressió, el `carat`, era una bona decisió car és la variable més rellevant en la regressió. Seguida de les variables dimensionals, que ja hem vist al principi que estan fortament correlacionades amb el pes, com és lògic.

### RMSE d'un random forest

La regressió lineal clàssica no deixa de ser un model senzill i podríem provar-ne de més avançats. Un model que podríem calcular és el de _random forest_, un model basat en arbres de decisió. La funció que utilitzarem (`ranger`) està composada de 500, per defecte. A continuació en calculem el model i l'error quadràtic mig (RMSE) del logaritme del preu contra les variables categòriques i el carat, que hem vist anteriorment que representa les altres dimensions.

```{r, echo=TRUE}
set.seed(8325)

diamondsid <- diamonds %>% mutate(id = row_number(), y = log(price))

rmse <- function(obs, pred) {
  sqrt(mean((obs - pred)^2))
}

# Calcular el model per un plec i evaluem-ne l'error
fit_on_fold <- function(fold, data) {
  fit <- ranger(y ~ carat + cut + color + clarity, data = data[fold, ])
  r <- rmse(data$y[-fold], predict(fit, data[-fold, ])$pred)
  c(r, fit$r.squared)
}

# Validació creuada bàsica amb 5 plecs
folds <- create_folds(diamondsid$id, k = 5, type = "basic")
fitavg <- rowMeans(sapply(folds, fit_on_fold, data = diamondsid))
fitavg
```

El model ens explica un 99% del dataset i té un rmse de 0.10. Millor que abans, tot i que fins i tot sona massa bé per ser veritat, però pot ser que realment aquest sigui un model ideal pel cas que ens ocupa.

## Conclusions

Després d'aquest anàlisi, podem concloure que la variable que més importa a l'hora de determinar el preu del diamant és el seu pes, així que és manté aquella imatge de les pel·lícules de voler oferir [un diamant ben gros ben gros](https://youtu.be/bfsnebJd-BI?t=136).

I doncs, **ja hem acabat?** Ja hauríem acabat si no fos pel resultat següent; agrupar el dataset per les seves variables categòriques, el carat i el preu [[Image 11](#dupes)].

[]{#dupes}

```{r fig.cap="Imatge 11: Percentatge de duplicats en el dataset"}

# We add group id and its size
dia <- diamonds %>%
  group_by(carat, cut, clarity, color, price) %>%
  mutate(id = cur_group_id(),
         id_size = n()) %>%
  ungroup() %>%
  arrange(id)

# Proportion of duplicates
dupes = 1 - max(dia$id) / nrow(dia)  # 0.26

pie(c(dupes, 1 - dupes), labels = c('duplicats', 'únics'), main="Proporció de duplicats")
```

Resulta que agafant aquestes variables, una quarta part del dataset té repetits! Podria ser casualitat, que per algun motiu desconegut diamants de dimensions diferents _ceteris paribus_ tingués el mateix preu, però ens hauria de fer desconfiar. Sense anar més lluny, hi ha un diamant de 2.01 carats en què l'únic que canvia són les dimensions i es va vendre pel mateix preu sis vegades, no serà el mateix diamant venut sis vegades?

Aquesta revelació podria potencialment invalidar tot l'anàlisi! Si tenim dades agrupades, el _random forests_ podria estar memoritzant aquests casos duplicats i quan n'evaluem l'error de manera aleatòria, estaríem treient una conclusió més optimista de la realitat i, en conseqüència, un model pitjor del què treuriem si netegéssim les dades.

A continuació n'evaluem l'impacte i comentarem maneres de superar el problema.

## Com superar el problema

**Avaluació de l'impacte**

El què farem és repetir vàries vegades particions del nostre dataset (validació creuada) utilitzant dues tècniques diferents: bàsica i agrupada. En la variant agrupada, assegurem que les files del mateix grup cauen en un mateix plec, evitant així la tendència a recompensar el sobreajustament d'aquestes estratègies de validació. La bàsica és la que ja hem fet abans.

[](#impact)

```{r fig.cap="Imatge 12: Impacte dels duplicats en un RMSE"}
set.seed(8325)

dia <- diamonds %>%
  group_by(carat, cut, clarity, color, price) %>%
  mutate(id = cur_group_id(),
         id_size = n()) %>%
  ungroup() %>%
  arrange(id)

dia <- dia %>%
  mutate(y = log(price))

rmse <- function(obs, pred) {
  sqrt(mean((obs - pred)^2))
}

# Calcular el model per un plec i evaluem-ne l'error
fit_on_fold <- function(fold, data) {
  fit <- ranger(y ~ carat + cut + color + clarity, data = data[fold, ])
  rmse(data$y[-fold], predict(fit, data[-fold, ])$pred)
}

# Validació creuada amb 5-plecs, tant bàsica com per grups
cross_validate <- function(type, data) {
  folds <- create_folds(data$id, k = 5, type = type)
  mean(sapply(folds, fit_on_fold, data = dia))
}

# Apply and plot
results <- sapply(c("basic", "grouped"), cross_validate, data = dia)

barplot(results, col = "orange", ylab = "RMSE via validació creuada 5-fold")
```

A la [[Imatge 12](#impact)] veiem com en una evaluació naïf de l'error creuriem que el nostre model explica la variable observada un 1% millor que no pas si ho evaluem amb una estratègia robusta. Això és un error relatiu considerable, de gairebé un 10%.

Aquest resultat ens denota la importància de tenir bones estratègies de validació, sinó, podríem estar donant resultats incorrectes i no ho sabríem.

## Conclusions (ara si)

Hem pogut comprovar que la nostra conclusió anterior continua sent vàlida, però hauríem d'aprendre la lliçó més important de totes: vingui d'on vingui el dataset, **neteja les dades**. Encara caldria buscar dades impossibles (e.g. hi ha 20 diamants de mida 0) i per això cal també **entendre bé el dataset**. A partir d'aquí, podem treballar i treure bons models.

