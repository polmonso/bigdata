---
title: "Report sobre el conjunt de dades `diamonds`"
author: "Pol Monsó Purtí"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: 72
---

<style>
body {text-align: justify}
</style>

## Context

`diamonds` és un conjunt de dades del paquet ggplot2 que descriu 54000 diamants. Tot i que no he trobat massa informació fefaent sobre l'origen, sembla que és un dataset del 2008 fet per [Solomon](https://rpubs.com/anthonycerna/diamondspredictions). En aquest informe l'analitzarem, veurem quines _features_ són més rellevants a l'hora de determinar el preu i mirarem de fer algun model predictiu.


```{r include = FALSE}
knitr::opts_chunk$set(fig.align='center', echo=FALSE, message=FALSE, warning=FALSE)
```

```{r}
require('ggplot2')
require('corrplot')
require('ggridges')
require('ggpubr')
require('viridis')
require('tidyverse')
require('relaimpo')
require('ranger')
require('splitTools')

```

```{r}
library(ggplot2)
library(corrplot)
library(ggridges)
library(ggpubr)
library(viridis)
library(tidyverse)
library(dplyr)
library(relaimpo)
library(ranger)
library(splitTools)

data(diamonds)
```

## Referències

L'anàlisi del dataset ha seguit força algunes parts dels articles següents:

- [Garg - Diamonds what determines their price](https://12ft.io/proxy?q=https%3A%2F%2Fmedium.com%2Fcodex%2Fdiamonds-what-determines-their-price-264a83c7f61a)
- [Napitupulu - Diamonds' Analysis](http://napitupulu-jon.appspot.com/posts/diamonds-analysis.html)
- [Cerna - Diamonds Predictions](https://rpubs.com/anthonycerna/diamondspredictions)
- [Mayer - A curious fact on the diamonds dataset](https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/)
- [Diamond Search Engine](https://www.diamondse.info)
- [Standford dcl model](https://dcl-model.stanford.edu/understand_your_data.html)

En especial el segon i quart article. Recomanem que no llegiu l'article de Mayer fins al final de l'informe.

## Introducció

En aquest informe primer farem un anàlisi del dataset `diamonds`, a continuació veurem quines variables són més importants per explicar el preu d'un diamant i finalment calcularem algun model de predicció. Per acabar, treurem alguna conclusió sobre el conjunt de dades i com l'hem analitzat.

## Anàlisi del dataset

### Exploració superficial

```{r}
glimpse(diamonds)
```

D'entrada podem veure que el dataset té 10 característiques de les quals tres són categòriques i la majoria són quantitatives.

Sense anar més lluny, ja podem endevinar a què fan referència la major part de les variables. El color i el preu es refereixen al color del diamant i el preu de venta. Si explorem el color veiem que el rang de la variable és de D a J. Segons [Diamonds Search Engine](https://www.diamondse.info/diamonds-color.asp), la D és sense color i la J és el rang més opac dels transparents que no tenen color.

El tall és una variable categòrica que descriu la qualitat del tall, i la claredat, també. Segons la font anterior, els millors talls fan diamants més simètrics i lluminosos, mentre que la claredat es veu influenciada per micro escletxes i imperfeccions del diamant. Per tant, com menys imperfeccions tenim, millor és la claredat (`IF`) i viceversa (`I1`) ([Claredat](https://www.diamondse.info/diamonds-clarity.asp)).

Pel què fa a les dimensions, tenim `x`, `y`, `z`, `table`, `depth` i `carat`. `x`, `y` i `z` són les dimensions màximes/externes del diamant i _taula_ i _profunditat_ les mínimes/internes. La [imatge 1](#dimensions) iŀlustra bé com es defineixen aquestes dimensions.

I finalment, el pes d'un diamant es mesura en _carats_.

[]{#dimensions}

<center>
![Imatge 1: Explicació de les dimensions d'un diamant](https://raw.githubusercontent.com/polmonso/bigdata/master/images/diamonds.png)
</center>

La variable que més estudiarem serà la del preu. De quines variables depèn més? Quines són poc rellevants? D'entrada podem fer una ullada a la distribució d'aquest preu [[Imatge 1](#distribucio)] i observar que la majoria de diamants es venen per menys de dos mil dòlars. Per sobre de cinc mil tenim una cua exponencial decreixent amb poca freqüència que s'allarga fins a 18000 US$. En general la corba és exponencial decreixent amb un petit *plateau* de dos mil a cinc mil.

[]{#distribucio}

```{r foo,fig.cap="Imatge 1: Distribució del preu"}
ggplot(diamonds) + geom_histogram(aes(x = price)) + xlab("Preu del Diamant [US$]") + ylab("Freqüència")
```

Aquesta distribució tant esbiaixada fa que la mitjana i la mediana siguin molt diferents (3962.8 i 2401 respectivament), fent de la mediana una mesura més representativa de la centralitzat de les valors.

## Creuament de dades

### Variables númeriques

Un cop ja hem fet una ullada a la distribució del preu i tenim una idea del què podem esperar, podem explorar la correlació entre les variables que composen el dataset. Com més correlades estiguin més grans ens sortiran els cercles del gràfic de correlació [[Imatge 2](#correlacio)]. Això ens permetrà tenir una idea de quines variables numèriques són les més rellevants en determinar el preu.

[]{#correlacio}

```{r fig.cap="Imatge 2: Correlació de variables"}
num.Cols <- diamonds[,sapply(diamonds,is.numeric)]
corrplot(cor(num.Cols), method = "circle", type = "upper", addCoef.col = "black")
```

D'entrada ja podem veure que preu està fortament correlat amb les dimensions (x, y, z) i sobretot amb els carats. No és sorprenent que com més gran sigui el diamant, més car sigui, i també podem veure que més volum implica més carats de pes.

Una altra conclusió que podem treure, tot i que no correlaciona amb el preu, és que a major profunditat, menys taula té el diamant. Com que aquestes variables no correlacionen gaire amb el preu, en principi no caldrà estudiar-les gaire.

### Variables categòriques

Les variables categòriques són les que resultaran més interessants donat que llur correlació amb el preu és menys evident. El que farem per analitzar el tall, el color i la claredat és mostrar la distribució del preu per a cada valor de variable categòrica [[Imatge 3](#catcorr)].

Per a fer-ho dibuixarem la distribució del preu condicionada per la variable categòrica i també el diagrama de caixes per veure la mediana, els quantils i els valors més extrems (que, amb la distribució dels preus de l'anàlisi preliminar, ja podem anticipar que seran a la part més cara del gràfic).

[]{#catcorr}

```{r fig.cap="Imatge 3: Correlació amb el tall"}
p1 <- ggplot(diamonds, aes(x = price, y = cut, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) +
  ggtitle("Ridge plot preu contra tall")

cut_median <- summarise(group_by(diamonds, cut), MD = median(price))

p2 <- ggplot(diamonds) +
  geom_boxplot(aes(x = cut, y = price, color = cut)) +
  ggtitle("Preu del diamant per tall") +
  geom_text(data = cut_median, aes(cut, MD, label = MD), position = position_dodge(width = 0.8), size = 3, vjust = -0.5)

ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

Curiosament, el tall `Fair` és el què millor mediana té, contràriament al que hom esperaria. També és el que queda més concentrat. És potser perquè en realitat les altres variables són més importants? Explorem el color a la [[Imatge 4](#catcorrcolor)].

[]{#catcorrcolor}

```{r fig.cap="Imatge 4: Correlació amb el color"}
p1 <- ggplot(diamonds, aes(x = price, y = color, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) +
  ggtitle("Ridge plot preu vs color")

color_median <- summarise(group_by(diamonds, color), MD = median(price))

p2 <- ggplot(diamonds) +geom_boxplot(aes(x = color, y = price, color = color)) +
  ggtitle("Boxplot preu vs color") +
  geom_text(data = color_median, aes(color, MD, label = MD), position = position_dodge(width = 0.8), size = 3, vjust = -0.5)

ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

Aquí també tenim una sorpresa, hom pensaria que un diamant totalment transparent seria millor, però resulta que són més cars els que tenen una lleugera opacitat, continuen sent transparents, però menys que els del primer grup. El [Diamond Search Engine](https://www.diamondse.info/diamonds-color.asp) deia que els diamants transparents (`D`) eren els més rars, però si grafiquem la distribució per color [[Imatge 5](#districolor)], no és així en el nostre dataset.

[]{#districolor}

```{r fig.cap="Imatge 5: Distribució del color en el dataset"}
diamonds %>%
    ggplot(aes(color)) +
    geom_bar()
```

I finalment, si estudiem la claredat ([[Imatge 6](#catcorrclar)]), la claredat més valorada és la `S12`, donat que té la mediana més alta, seguit de `I1` i `SI1`. A més a més, podem veure en la distribució de l'`SI2` i l'`I1` que tenen més diamants en el sector més car en contraposició a les altres claredats, que tenen més concentració en el preu per sota de 2000. Qui més concentrat està en la part baixa són les claredats `IF` i `VVS1`.

[]{#catcorrclar}

```{r fig.cap="Imatge 6: Correlació amb la claredat"}
p1 <- ggplot(diamonds, aes(x = price, y = clarity, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(option = "A", direction = -1) +
  ggtitle("Ridge plot Preu vs Claredat")

clarity_median <- summarise(group_by(diamonds, clarity), MD = median(price))

p2 <- ggplot(diamonds) +geom_boxplot(aes(x = clarity, y = price, color = clarity)) +
  ggtitle("Boxplot Preu vs Claredat") +
  geom_text(data = clarity_median, aes(clarity, MD, label = MD), position = position_dodge(width = 0.8), size = 3, vjust = -0.5)

ggpubr::ggarrange(p1, p2, nrow = 1, ncol = 2)
```

## Models predictius

Un cop feta l'exploració del dataset, podem passar a mirar de determinar quina de les variables és més rellevant per determinar el preu d'un diamant.

Per a fer-ho, començarem per encaixar una regressió lineal amb les dades i n'observarem la coincidència [[Imatge 7](#lm)].

### Linear modeling

[]{#lm}

```{r fig.cap="Imatge 7: Fitting d'un model lineal", echo = TRUE}
lmMod <- lm(price~., data=diamonds)
summary(lmMod)
```

Aquest senzill model de regressió lineal explica el ~91% del preu basant-se en les altres variables. Dit d'una altra manera, donades unes dimensions, claredat, etc. si ho multipliquem per l'estimació dels coeficients resultat de la regressió i hi sumem l'_intercept_, tindrem una estimació del preu que tindria aquell hipotètic diamant.

També podríem mirar de millorar la regressió a partir de _least squares_ i seleccionar variables [[Imatge 8](#lmlog)], o bé mirar de quadrar un model bayesià com `stan_glm` del paquet `rstanarm`.

[]{#lmlog}

```{r fig.cap="Imatge 8: Fitting d'un model lineal via least squares respecte els carats", echo = TRUE}
lmMod <- lm(log(price) ~ log(carat), data=diamonds)
summary(lmMod)
```

Però el què ens interessa avaluar és la importància de cada variable per a saber millor de què depèn el preu i respondre la pregunta de la què hem partit en el nostre anàlisi. Per a fer-ho, ho passem per la funció `relaimpo` que ens mostra la importància relativa de cada variable en la [[Imatge 9](#relaimpo)].

[]{#relaimpo}

```{r fig.cap="Imatge 9: Importància de cada variable en la regressió"}
lmMod <- lm(price~., data=diamonds)

importance <- calc.relimp(lmMod, type = "lmg", rela = F)

plot(importance, main="Importància de cada variable en la regressió contra preu")
```

Ja podem veure que la tria de [la segona regressió](#lmlog), el `carat`, era una bona decisió car és la variable més rellevant en la regressió. El segueixen les variables dimensionals, que ja hem vist al principi que estan fortament correlacionades amb el pes, com és lògic.

### RMSE d'un random forest

La regressió lineal clàssica no deixa de ser un model senzill i podríem provar-ne de més avançats. Un model que podríem calcular és el de _random forest_, un model basat en arbres de decisió. La funció que utilitzarem (`ranger`) està composada de 500, per defecte.

A continuació en calculem el model i l'error quadràtic mig (RMSE) del logaritme del preu contra les variables categòriques i el carat, que hem vist anteriorment que representa les altres dimensions. A més a més, farem la validació creuada mitja de cinc particions de les dades per a tenir una millor estimació de la qualitat del model.

```{r, echo=TRUE}
set.seed(8325)

diamondsid <- diamonds %>% mutate(id = row_number(), y = log(price))

rmse <- function(obs, pred) {
  sqrt(mean((obs - pred)^2))
}

# Calcular el model per un plec i evaluem-ne l'error
fit_on_fold <- function(fold, data) {
  fit <- ranger(y ~ carat + cut + color + clarity, data = data[fold, ])
  r <- rmse(data$y[-fold], predict(fit, data[-fold, ])$pred)
  c(r, fit$r.squared)
}

# Validació creuada bàsica amb 5 plecs
folds <- create_folds(diamondsid$id, k = 5, type = "basic")
fitavg <- rowMeans(sapply(folds, fit_on_fold, data = diamondsid))
fitavg
```

El model ens explica un 99% del dataset i té un rmse de 0.10. Millor que abans, i fins i tot sona massa bé per ser veritat, però pot ser que realment aquest sigui un model ideal pel cas que ens ocupa. Amb aquest model, podríem predir el preu de mercat del diamant en el context del conjunt de dades, que molt probablement necessitaria ajustaments o conjunts de dades més recents per a ser aplicat avui.

## Conclusions

Després d'aquest anàlisi, podem concloure que la variable que més importa a l'hora de determinar el preu del diamant és el seu pe. Hem après què valorar i què mirar si mai hem de triar un diamant. Segons aquest conjunt de dades, es manté la imatge de les peŀlícules de voler oferir [un diamant ben gros ben gros](https://youtu.be/bfsnebJd-BI?t=136).

I doncs, **ja hem acabat?** Semblaria que si, i ja hauríem acabat si no fos pel resultat següent; agrupar el dataset per les seves variables categòriques, el carat i el preu dóna el resultat de la [[Image 11](#dupes)].

[]{#dupes}

```{r fig.cap="Imatge 11: Percentatge de duplicats en el dataset"}

# We add group id and its size
dia <- diamonds %>%
  group_by(carat, cut, clarity, color, price) %>%
  mutate(id = cur_group_id(),
         id_size = n()) %>%
  ungroup() %>%
  arrange(id)

# Proportion of duplicates
dupes = 1 - max(dia$id) / nrow(dia)  # 0.26

pie(c(dupes, 1 - dupes), labels = c('duplicats', 'únics'), main="Proporció de duplicats")
```

Resulta que agrupant les dades per les variables categòriques, el pes i el preu, una quarta part del dataset té repetits! Podria ser casualitat, que, per algun motiu desconegut, diamants de dimensions diferents _ceteris paribus_ tinguessin el mateix preu, però ens hauria de fer desconfiar. Sense anar més lluny, hi ha un diamant de 2.01 carats en què l'únic que canvia són les dimensions i es va vendre pel mateix preu sis vegades, no serà el mateix diamant venut sis vegades?

Aquesta revelació podria potencialment invalidar tot l'anàlisi! Si tenim dades agrupades, el _random forests_ podria estar memoritzant aquests casos duplicats i quan n'avaluem l'error de manera aleatòria, estaríem treien una conclusió més optimista de la realitat i, en conseqüència, un model pitjor del què treuriem si netegéssim les dades.

A continuació n'avaluem l'impacte i comentarem maneres de superar el problema.

## Com superar el problema

**Avaluació de l'impacte**

Com abans, el què farem és repetir vàries vegades particions del nostre dataset (validació creuada) però ara utilitzant dues tècniques diferents: bàsica i agrupada. En la variant agrupada, assegurem que les files del mateix grup cauen en un mateix plec, evitant així la tendència a recompensar el sobreajustament d'aquestes estratègies de validació. La bàsica és la que ja hem fet abans.

[](#impact)

```{r fig.cap="Imatge 12: Impacte dels duplicats en un RMSE"}
set.seed(8325)

dia <- diamonds %>%
  group_by(carat, cut, clarity, color, price) %>%
  mutate(id = cur_group_id(),
         id_size = n()) %>%
  ungroup() %>%
  arrange(id)

dia <- dia %>%
  mutate(y = log(price))

rmse <- function(obs, pred) {
  sqrt(mean((obs - pred)^2))
}

# Calcular el model per un plec i evaluem-ne l'error
fit_on_fold <- function(fold, data) {
  fit <- ranger(y ~ carat + cut + color + clarity, data = data[fold, ])
  rmse(data$y[-fold], predict(fit, data[-fold, ])$pred)
}

# Validació creuada amb 5-plecs, tant bàsica com per grups
cross_validate <- function(type, data) {
  folds <- create_folds(data$id, k = 5, type = type)
  mean(sapply(folds, fit_on_fold, data = dia))
}

# Apply and plot
results <- sapply(c("basic", "grouped"), cross_validate, data = dia)

barplot(results, col = "orange", ylab = "RMSE via validació creuada 5-fold")
```

A la [[Imatge 12](#impact)] veiem com, en una avaluació naïf de l'error, creuríem que el nostre model explica la variable observada un 1% millor que no pas si ho avaluem amb una estratègia robusta. Això és un error relatiu considerable, de gairebé un 10%.

Aquest resultat ens denota la importància de tenir bones estratègies de validació, sinó, podríem estar donant resultats incorrectes i no ho sabríem.

## Conclusions (ara si)

Hem pogut comprovar que la nostra conclusió anterior continua sent vàlida, però hauríem d'aprendre la lliçó més important de totes: vingui d'on vingui el dataset, **neteja les dades**. Encara caldria buscar dades impossibles (e.g. hi ha 20 diamants de mida 0) i per això cal també **entendre bé el dataset**. A partir d'aquí, podem treballar i treure bons models.


